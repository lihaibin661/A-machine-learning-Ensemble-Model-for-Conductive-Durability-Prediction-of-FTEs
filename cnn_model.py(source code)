# cnn_model.py
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import mean_squared_error

# Load data for the CNN model from "600CNN5.13.csv"
data = pd.read_csv('data/600CNN5.13.csv')  # Adjust the path accordingly

# Split the "ZTO/Ag" column into two separate features
data[['ZTO', 'Ag']] = data['ZTO/Ag'].str.split(',', expand=True)
data['ZTO'] = pd.to_numeric(data['ZTO'])
data['Ag'] = pd.to_numeric(data['Ag'])

# One-hot encode the "ZTO" and "Ag" features
encoder = OneHotEncoder(sparse=False)
encoded = encoder.fit_transform(data[['ZTO', 'Ag']])

# Concatenate the encoded features with additional numerical features: "Number of Bending" and "Storage time"
X = np.hstack((encoded, data[['Number of Bending', 'Storage time']].values))
y = data['Square resistance'].values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Reshape input data for Conv1D layers: (samples, features, channels)
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Build the CNN model
model = tf.keras.Sequential([
    tf.keras.layers.Conv1D(64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(50, activation='relu'),
    tf.keras.layers.Dense(1)
])
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the CNN model for 100 epochs (with 20% validation split)
history = model.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=1)

# Predict on the test set
predictions = model.predict(X_test).flatten()

# Evaluate the model
mse = mean_squared_error(y_test, predictions)
print("CNN Model Test MSE: {:.4f}".format(mse))

# Save the predictions for the stacking ensemble
pd.DataFrame({'cnn_pred': predictions}).to_csv('cnn_predictions.csv', index=False)
